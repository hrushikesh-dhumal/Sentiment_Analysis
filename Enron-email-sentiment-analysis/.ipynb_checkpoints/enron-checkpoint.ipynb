{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read CSV\n",
    "import csv\n",
    "lines = csv.reader(open('data\\enron.csv'), delimiter=',', quotechar='\"')\n",
    "\n",
    "# Iterate over 'lines' and insert the into a list of dictionaries\n",
    "header = []\n",
    "emails = []\n",
    "for row in lines:      # csv module lacks unicode support!\n",
    "    line = [unicode(cell, 'utf-8') for cell in row]\n",
    "    if not header:     # Read the first line as header\n",
    "        header = line\n",
    "        continue   \n",
    "    emails.append(dict(zip(header, line)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'System',\n",
       " u'Notification',\n",
       " u':',\n",
       " u'At',\n",
       " u'0115',\n",
       " u'PST',\n",
       " u',',\n",
       " u'WACM',\n",
       " u'terminated',\n",
       " u'request',\n",
       " u'for',\n",
       " u'coordinated',\n",
       " u'operation',\n",
       " u'controllable',\n",
       " u'devices',\n",
       " u'for',\n",
       " u'Path',\n",
       " u'30',\n",
       " u'USF',\n",
       " u'mitigation',\n",
       " u'.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get words from first abstract\n",
    "import nltk\n",
    "nltk.word_tokenize(emails[0]['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'system',\n",
       " u'notification',\n",
       " u':',\n",
       " u'at',\n",
       " u'0115',\n",
       " u'pst',\n",
       " u',',\n",
       " u'wacm',\n",
       " u'terminated',\n",
       " u'request',\n",
       " u'for',\n",
       " u'coordinated',\n",
       " u'operation',\n",
       " u'controllable',\n",
       " u'devices',\n",
       " u'for',\n",
       " u'path',\n",
       " u'30',\n",
       " u'usf',\n",
       " u'mitigation',\n",
       " u'.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lower case words. 'string' module from Python library\n",
    "import string\n",
    "map(string.lower, nltk.word_tokenize(emails[0]['body']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now for all emails\n",
    "for email in emails:\n",
    "    words = map(string.lower, nltk.word_tokenize(email['body']))\n",
    "    email.update({'words': words})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Double list comprehension\n",
    "all_words = [ word for email in emails for word in email['words'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "483"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique words\n",
    "len(set(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   74 .\n",
      "   46 the\n",
      "   43 to\n",
      "   43 i\n",
      "   28 ,\n"
     ]
    }
   ],
   "source": [
    "# Word count\n",
    "wordcounts = {}\n",
    "for term in all_words:\n",
    "    wordcounts[term] = wordcounts.get(term, 0) + 1\n",
    "\n",
    "# Change the ordering of value and key for sorting\n",
    "items = [(v, k) for k, v in wordcounts.items()]\n",
    "\n",
    "# for all for count, word in sorted(items, reverse=True):\n",
    "for count, word in sorted(items, reverse=True)[:5]:\n",
    "    print(\"%5d %s\" % (count, word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   13 notice\n",
      "   11 market\n",
      "   10 system\n",
      "   10 iso\n",
      "    9 change\n"
     ]
    }
   ],
   "source": [
    "# Filter out common words\n",
    "import nltk.corpus\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "terms = {}\n",
    "for word, count in wordcounts.iteritems():\n",
    "    if count > 2 and word not in stopwords and word.isalpha():\n",
    "        terms[word] = count\n",
    "\n",
    "\n",
    "# Change the ordering of value and key for sorting\n",
    "items = [(v, k) for k, v in terms.items()]\n",
    "\n",
    "for count, word in sorted(items, reverse=True)[:5]:\n",
    "    print(\"%5d %s\" % (count, word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   11 market\n",
      "   10 system\n",
      "   10 iso\n",
      "    9 change\n",
      "    8 conditions\n"
     ]
    }
   ],
   "source": [
    "# Pop common words\n",
    "terms.pop('notice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   11 market\n",
      "   10 system\n",
      "   10 iso\n",
      "    9 change\n",
      "    8 conditions\n",
      "    6 time\n",
      "    6 path\n",
      "    5 subject\n",
      "    5 sent\n",
      "    5 request\n",
      "    5 little\n",
      "    5 information\n",
      "    4 suddenly\n",
      "    4 reflect\n",
      "    4 really\n",
      "    4 real\n",
      "    4 pricing\n",
      "    4 preparing\n",
      "    4 please\n",
      "    4 may\n",
      "    4 life\n",
      "    4 later\n",
      "    4 dynamic\n",
      "    4 described\n",
      "    4 current\n",
      "    4 communication\n",
      "    4 beep\n",
      "    4 available\n",
      "    4 attempted\n",
      "    4 accurate\n",
      "    3 way\n",
      "    3 two\n",
      "    3 participants\n",
      "    3 operations\n",
      "    3 operation\n",
      "    3 one\n",
      "    3 new\n",
      "    3 mw\n",
      "    3 june\n",
      "    3 july\n",
      "    3 introduction\n",
      "    3 go\n",
      "    3 flows\n",
      "    3 desk\n",
      "    3 communications\n",
      "    3 california\n",
      "    3 brendan\n"
     ]
    }
   ],
   "source": [
    "# View the list\n",
    "items = [(v, k) for k, v in terms.items()]\n",
    "\n",
    "for count, word in sorted(items, reverse=True):\n",
    "    print(\"%5d %s\" % (count, word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the dictionary to a list.\n",
    "terms = list(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Start Machine learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
